var X="AWS4-HMAC-SHA256",j="aws4_request",q="s3",ge="2",R="UNSIGNED-PAYLOAD",pe="application/octet-stream",J="application/xml",S="application/json",Re=["accessKeyId","secretAccessKey","sessionToken","password"],E="x-amz-content-sha256",Ee="x-amz-date",we="host",ye="Authorization",O="Content-Type",N="Content-Length",Y="etag",Z="last-modified",_="ultralight-s3 Module: ",me=`${_}accessKeyId must be a non-empty string`,Oe=`${_}secretAccessKey must be a non-empty string`,$e=`${_}endpoint must be a non-empty string`,Te=`${_}bucketName must be a non-empty string`,ee=`${_}key must be a non-empty string`,x=`${_}uploadId must be a non-empty string`,te=`${_}parts must be a non-empty array`,re=`${_}Each part must have a partNumber (number) and ETag (string)`,F=`${_}data must be a Buffer or string`,se=`${_}prefix must be a string`,ie=`${_}maxKeys must be a positive integer`,ae=`${_}delimiter must be a string`,oe=crypto.createHmac||(await import("node:crypto")).createHmac,ne=crypto.createHash||(await import("node:crypto")).createHash;typeof oe>"u"&&typeof ne>"u"&&console.error("ultralight-S3 Module: Crypto functions are not available, please report the issue with necessary description: https://github.com/sentienhq/ultralight-s3/issues");var Ie={contents:!0},Ae=t=>`%${t.charCodeAt(0).toString(16).toUpperCase()}`,K=t=>encodeURIComponent(t).replace(/[!'()*]/g,Ae),y=t=>K(t).replace(/%2F/g,"/"),he=class{constructor({accessKeyId:t,secretAccessKey:e,endpoint:r,bucketName:s,region:i="auto",maxRequestSizeInBytes:o=5242880,requestAbortTimeout:n=void 0,logger:u=void 0}){this.getBucketName=()=>this.bucketName,this.setBucketName=a=>{this.bucketName=a},this.getRegion=()=>this.region,this.setRegion=a=>{this.region=a},this.getEndpoint=()=>this.endpoint,this.setEndpoint=a=>{this.endpoint=a},this.getMaxRequestSizeInBytes=()=>this.maxRequestSizeInBytes,this.setMaxRequestSizeInBytes=a=>{this.maxRequestSizeInBytes=a},this.sanitizeETag=a=>L(a),this.getProps=()=>({accessKeyId:this.accessKeyId,secretAccessKey:this.secretAccessKey,region:this.region,bucket:this.bucketName,endpoint:this.endpoint,maxRequestSizeInBytes:this.maxRequestSizeInBytes,requestAbortTimeout:this.requestAbortTimeout,logger:this.logger}),this.setProps=a=>{this._validateConstructorParams(a.accessKeyId,a.secretAccessKey,a.bucketName,a.endpoint),this.accessKeyId=a.accessKeyId,this.secretAccessKey=a.secretAccessKey,this.region=a.region||"auto",this.bucketName=a.bucketName,this.endpoint=a.endpoint,this.maxRequestSizeInBytes=a.maxRequestSizeInBytes||5242880,this.requestAbortTimeout=a.requestAbortTimeout,this.logger=a.logger},this._validateConstructorParams(t,e,r,s),this.accessKeyId=t,this.secretAccessKey=e,this.endpoint=r,this.bucketName=s,this.region=i,this.maxRequestSizeInBytes=o,this.requestAbortTimeout=n,this.logger=u}_validateConstructorParams(t,e,r,s){if(typeof t!="string"||t.trim().length===0)throw new TypeError(me);if(typeof e!="string"||e.trim().length===0)throw new TypeError(Oe);if(typeof r!="string"||r.trim().length===0)throw new TypeError($e);if(typeof s!="string"||s.trim().length===0)throw new TypeError(Te)}_checkMethodHeadnGet(t){if(t!=="GET"&&t!=="HEAD")throw this._log("error",`${_}method must be either GET or HEAD`),new Error("method must be either GET or HEAD")}_checkKey(t){if(typeof t!="string"||t.trim().length===0)throw this._log("error",ee),new TypeError(ee)}_checkDelimiter(t){if(typeof t!="string"||t.trim().length===0)throw this._log("error",ae),new TypeError(ae)}_checkPrefix(t){if(typeof t!="string")throw this._log("error",se),new TypeError(se)}_checkMaxKeys(t){if(typeof t!="number"||t<=0)throw this._log("error",ie),new TypeError(ie)}_checkOpts(t){if(typeof t!="object")throw this._log("error",`${_}opts must be an object`),new TypeError(`${_}opts must be an object`)}_log(t,e,r={}){if(this.logger&&typeof this.logger[t]=="function"){let s=n=>typeof n!="object"||n===null?n:Object.keys(n).reduce((u,a)=>(Re.includes(a.toLowerCase())?u[a]="[REDACTED]":typeof n[a]=="object"&&n[a]!==null?u[a]=s(n[a]):u[a]=n[a],u),Array.isArray(n)?[]:{}),i=s(r),o={timestamp:new Date().toISOString(),level:t,message:e,...i,context:s({bucketName:this.bucketName,region:this.region,endpoint:this.endpoint,accessKeyId:this.accessKeyId?`${this.accessKeyId.substring(0,4)}...`:void 0})};this.logger[t](o)}}async getContentLength(t){this._checkKey(t);let e={[E]:R},r=y(t),{url:s,headers:i}=await this._sign("HEAD",r,{},e,""),o=(await this._sendRequest(s,"HEAD",i)).headers.get(N);return o?parseInt(o,10):0}async bucketExists(){let t={[E]:R},{url:e,headers:r}=await this._sign("HEAD","",{},t,""),s=await this._sendRequest(e,"HEAD",r);return!!(s.ok&&s.status===200)}async fileExists(t,e={}){this._checkKey(t);let{filteredOpts:r,conditionalHeaders:s}=this._filterIfHeaders(e),i={[E]:R,...s},o=y(t),{url:n,headers:u}=await this._sign("HEAD",o,r,i,"");try{let a=await this._sendRequest(n,"HEAD",u,"",[200,404,412,304]);return a.status===404?!1:a.status===412||a.status===304?null:a.ok&&a.status===200?!0:(this._handleErrorResponse(a),!1)}catch(a){let c=a instanceof Error?a.message:String(a);throw this._log("error",`${_}Failed to check if file exists: ${c}`),new Error(`${_}Failed to check if file exists: ${c}`)}}async _sign(t,e,r,s,i){let o=new Date().toISOString().replace(/[:-]|\.\d{3}/g,""),n=typeof e=="string"&&e.length>0?new URL(e,this.endpoint):new URL(this.endpoint);n.pathname=`/${encodeURI(this.bucketName)}${n.pathname}`,s[E]=i?await H(i):R,s[Ee]=o,s[we]=n.host;let u=this._buildCanonicalHeaders(s),a=Object.keys(s).map(m=>m.toLowerCase()).sort().join(";"),c=await this._buildCanonicalRequest(t,n,r,u,a,i),f=await this._buildStringToSign(o,c),g=await this._calculateSignature(o,f),w=this._buildAuthorizationHeader(o,a,g);return s[ye]=w,{url:n.toString(),headers:s}}_buildCanonicalHeaders(t){return Object.entries(t).map(([e,r])=>`${e.toLowerCase()}:${String(r).trim()}`).sort().join(`
`)}async _buildCanonicalRequest(t,e,r,s,i,o){return[t,e.pathname,this._buildCanonicalQueryString(r),`${s}
`,i,o?await H(o):R].join(`
`)}async _buildStringToSign(t,e){let r=[t.slice(0,8),this.region,q,j].join("/");return[X,t,r,await H(e)].join(`
`)}async _calculateSignature(t,e){let r=await this._getSignatureKey(t.slice(0,8));return U(r,e,"hex")}_buildAuthorizationHeader(t,e,r){let s=[t.slice(0,8),this.region,q,j].join("/");return[`${X} Credential=${this.accessKeyId}/${s}`,`SignedHeaders=${e}`,`Signature=${r}`].join(", ")}_filterIfHeaders(t){let e={},r={},s=["if-match","if-none-match","if-modified-since","if-unmodified-since"];for(let[i,o]of Object.entries(t))s.includes(i)?r[i]=o:e[i]=o;return{filteredOpts:e,conditionalHeaders:r}}async list(t="/",e="",r=1e3,s="GET",i={}){this._checkDelimiter(t),this._checkPrefix(e),this._checkMaxKeys(r),this._checkMethodHeadnGet(s),this._checkOpts(i),this._log("info",`Listing objects in ${e}`);let o={"list-type":ge,"max-keys":String(r),...i};e.length>0&&(o.prefix=e);let n={[O]:S,[E]:R},u=t==="/"?t:K(t),{url:a,headers:c}=await this._sign("GET",u,o,n,""),f=`${a}?${new URLSearchParams(o)}`,g=await this._sendRequest(f,"GET",c),w=await g.text();if(s==="HEAD"){let b=g.headers.get(N),C=g.headers.get(Z),fe=g.headers.get(Y);return{size:b?+b:void 0,mtime:C?new Date(C):void 0,ETag:fe||void 0}}let m=D(w),M=m.listBucketResult||m.error||m;return M.contents||M}async listMultiPartUploads(t="/",e="",r="GET",s={}){var i,o,n;this._checkDelimiter(t),this._checkPrefix(e),this._checkMethodHeadnGet(r),this._checkOpts(s),this._log("info",`Listing multipart uploads in ${e}`);let u={uploads:"",...s},a={[O]:S,[E]:R},c=t==="/"?t:K(t),{url:f,headers:g}=await this._sign("GET",c,u,a,""),w=`${f}?${new URLSearchParams(u)}`,m=await this._sendRequest(w,"GET",g),M=await m.text();if(r==="HEAD")return{size:+((i=m.headers.get(N))!==null&&i!==void 0?i:"0"),mtime:new Date((o=m.headers.get(Z))!==null&&o!==void 0?o:""),ETag:(n=m.headers.get(Y))!==null&&n!==void 0?n:""};let b=D(M),C=b.listMultipartUploadsResult||b.error||b;return C.uploads||C}async get(t,e={}){this._checkKey(t),this._log("info",`Getting object ${t}`);let{filteredOpts:r,conditionalHeaders:s}=this._filterIfHeaders(e),i={[O]:S,[E]:R,...s},o=y(t),{url:n,headers:u}=await this._sign("GET",o,r,i,""),a=await this._sendRequest(n,"GET",u,"",[200,404,412,304]);if(a.status===404||a.status===412||a.status===304)return this._log("error",`Failed to get object. Status: ${a.status}`),null;if(!a.ok)throw this._log("error",`Failed to get object. Status: ${a.status}`),new Error(`Failed to get object. Status: ${a.status}`);return a.text()}async getObjectWithETag(t,e={}){this._checkKey(t),this._log("info",`Getting object ${t}`);let{filteredOpts:r,conditionalHeaders:s}=this._filterIfHeaders(e),i={[O]:S,[E]:R,...s},o=y(t),{url:n,headers:u}=await this._sign("GET",o,r,i,"");try{let a=await this._sendRequest(n,"GET",u,"",[200,404,412,304]);if(a.status===404||a.status===412||a.status===304)return this._log("error",`Failed to get object. Status: ${a.status}`),{etag:null,data:null};if(!a.ok)throw this._log("error",`Failed to get object. Status: ${a.status}`),new Error(`Failed to get object. Status: ${a.status}`);let c=a.headers.get("etag");if(!c)throw new Error("ETag not found in response headers");let f=await a.text();return{etag:L(c),data:f}}catch(a){throw this._log("error",`Error getting object ${t} with ETag: ${a}`),a}}async getEtag(t,e={}){this._checkKey(t),this._log("info",`Getting etag object ${t}`);let{filteredOpts:r,conditionalHeaders:s}=this._filterIfHeaders(e),i={[O]:S,[E]:R,...s},o=y(t),{url:n,headers:u}=await this._sign("HEAD",o,r,i,""),a=await this._sendRequest(n,"HEAD",u,"",[200,412,304]);if(this._log("info",`Response status: ${a.status,a.statusText}`),a.status===412||a.status===304)return null;let c=a.headers.get("etag");if(!c)throw this._log("error","ETag not found in response headers"),new Error("ETag not found in response headers");return L(c)}async getResponse(t,e=!0,r=0,s=this.maxRequestSizeInBytes,i={}){this._checkKey(t);let{filteredOpts:o,conditionalHeaders:n}=this._filterIfHeaders({...i}),u={[O]:S,[E]:R,...e?{}:{range:`bytes=${r}-${s-1}`},...n},a=y(t),{url:c,headers:f}=await this._sign("GET",a,o,u,""),g=`${c}?${new URLSearchParams(o)}`;return this._sendRequest(g,"GET",f)}async put(t,e){if(this._checkKey(t),!(e instanceof Buffer||typeof e=="string"))throw this._log("error",F),new TypeError(F);this._log("info",`Uploading object ${t}`);let r=typeof e=="string"?Buffer.byteLength(e):e.length,s={[N]:r},i=y(t),{url:o,headers:n}=await this._sign("PUT",i,{},s,e);return await this._sendRequest(o,"PUT",n,e)}async getMultipartUploadId(t,e=pe){if(this._checkKey(t),typeof e!="string")throw this._log("error",`${_}fileType must be a string`),new TypeError(`${_}fileType must be a string`);this._log("info",`Initiating multipart upload for object ${t}`);let r={uploads:""},s={[O]:e,[E]:R},i=y(t),{url:o,headers:n}=await this._sign("POST",i,r,s,""),u=`${o}?${new URLSearchParams(r)}`,a=await(await this._sendRequest(u,"POST",n)).text(),c=D(a);if(typeof c=="object"&&c!==null&&"error"in c&&typeof c.error=="object"&&c.error!==null&&"message"in c.error){let f=String(c.error.message);throw this._log("error",`${_}Failed to abort multipart upload: ${f}`),new Error(`${_}Failed to abort multipart upload: ${f}`)}if(typeof c=="object"&&c!==null){if(!c.initiateMultipartUploadResult||!c.initiateMultipartUploadResult.uploadId)throw this._log("error",`${_}Failed to create multipart upload: no uploadId in response`),new Error(`${_}Failed to create multipart upload: Missing upload ID in response`);return c.initiateMultipartUploadResult.uploadId}else throw this._log("error",`${_}Failed to create multipart upload: unexpected response format`),new Error(`${_}Failed to create multipart upload: Unexpected response format`)}async uploadPart(t,e,r,s,i={}){this._validateUploadPartParams(t,e,r,s,i);let o={uploadId:r,partNumber:s,...i},n={[N]:e.length},u=y(t),{url:a,headers:c}=await this._sign("PUT",u,o,n,e),f=`${a}?${new URLSearchParams(o)}`,g=await this._sendRequest(f,"PUT",c,e),w=L(g.headers.get("etag")||"");return{partNumber:s,ETag:w}}_validateUploadPartParams(t,e,r,s,i){if(this._checkKey(t),!(e instanceof Buffer||typeof e=="string"))throw this._log("error",F),new TypeError(F);if(typeof r!="string"||r.trim().length===0)throw this._log("error",x),new TypeError(x);if(!Number.isInteger(s)||s<=0)throw this._log("error",`${_}partNumber must be a positive integer`),new TypeError(`${_}partNumber must be a positive integer`);this._checkOpts(i)}async completeMultipartUpload(t,e,r){if(this._checkKey(t),typeof e!="string"||e.trim().length===0)throw this._log("error",x),new TypeError(x);if(!Array.isArray(r)||r.length===0)throw this._log("error",te),new TypeError(te);if(!r.every(w=>typeof w.partNumber=="number"&&typeof w.ETag=="string"))throw this._log("error",re),new TypeError(re);this._log("info",`Complete multipart upload ${e} for object ${t}`);let s={uploadId:e},i=this._buildCompleteMultipartUploadXml(r),o={[O]:J,[N]:Buffer.byteLength(i).toString(),[E]:await H(i)},n=y(t),{url:u,headers:a}=await this._sign("POST",n,s,o,i),c=`${u}?${new URLSearchParams(s)}`,f=await(await this._sendRequest(c,"POST",a,i)).text(),g=D(f);if(typeof g=="object"&&g!==null&&"error"in g&&typeof g.error=="object"&&g.error!==null&&"message"in g.error){let w=String(g.error.message);throw this._log("error",`${_}Failed to abort multipart upload: ${w}`),new Error(`${_}Failed to abort multipart upload: ${w}`)}return g.completeMultipartUploadResult}async abortMultipartUpload(t,e){if(this._checkKey(t),typeof e!="string"||e.trim().length===0)throw this._log("error",x),new TypeError(x);this._log("info",`Aborting multipart upload ${e} for object ${t}`);let r={uploadId:e},s={[O]:J,[E]:R};try{let i=y(t),{url:o,headers:n}=await this._sign("DELETE",i,r,s,""),u=`${o}?${new URLSearchParams(r)}`,a=await this._sendRequest(u,"DELETE",n);if(a.ok){let c=await a.text(),f=D(c);if(typeof f=="object"&&f!==null&&"error"in f&&typeof f.error=="object"&&f.error!==null&&"message"in f.error){let g=String(f.error.message);throw this._log("error",`${_}Failed to abort multipart upload: ${g}`),new Error(`${_}Failed to abort multipart upload: ${g}`)}return{status:"Aborted",key:t,uploadId:e,response:f}}else throw this._log("error",`${_}Abort request failed with status ${a.status}`),new Error(`${_}Abort request failed with status ${a.status}`)}catch(i){let o=i instanceof Error?i.message:String(i);throw this._log("error",`${_}Failed to abort multipart upload for key ${t}: ${o}`),new Error(`${_}Failed to abort multipart upload for key ${t}: ${o}`)}}_buildCompleteMultipartUploadXml(t){return`
      <CompleteMultipartUpload>
        ${t.map(e=>`
          <Part>
            <PartNumber>${e.partNumber}</PartNumber>
            <ETag>${e.ETag}</ETag>
          </Part>
        `).join("")}
      </CompleteMultipartUpload>
    `}async delete(t){this._checkKey(t),this._log("info",`Deleting object ${t}`);let e={[O]:S,[E]:R},r=y(t),{url:s,headers:i}=await this._sign("DELETE",r,{},e,""),o=await this._sendRequest(s,"DELETE",i);return o.status===204||o.status===200}async _sendRequest(t,e,r,s,i=[]){this._log("info",`Sending ${e} request to ${t}, headers: ${JSON.stringify(r)}`);let o=await fetch(t,{method:e,headers:r,body:["GET","HEAD"].includes(e)?void 0:s,signal:this.requestAbortTimeout!==void 0?AbortSignal.timeout(this.requestAbortTimeout):void 0});return!o.ok&&!i.includes(o.status)&&await this._handleErrorResponse(o),o}async _handleErrorResponse(t){let e=await t.text(),r=t.headers.get("x-amz-error-code")||"Unknown",s=t.headers.get("x-amz-error-message")||t.statusText;throw this._log("error",`${_}Request failed with status ${t.status}: ${r} - ${s},err body: ${e}`),new Error(`${_}Request failed with status ${t.status}: ${r} - ${s}, err body: ${e}`)}_buildCanonicalQueryString(t){return Object.keys(t).length<1?"":Object.keys(t).sort().map(e=>`${encodeURIComponent(e)}=${encodeURIComponent(t[e])}`).join("&")}async _getSignatureKey(t){let e=await U(`AWS4${this.secretAccessKey}`,t),r=await U(e,this.region),s=await U(r,q);return U(s,j)}},H=async t=>{let e=ne("sha256");return e.update(t),e.digest("hex")},U=async(t,e,r)=>{let s=oe("sha256",t);return s.update(e),s.digest(r)},L=t=>{let e={'"':"","&quot;":"","&#34;":"","&QUOT;":"","&#x00022":""};return t.replace(/^("|&quot;|&#34;)|("|&quot;|&#34;)$/g,r=>e[r])},D=t=>{let e=o=>o.replace(/&quot;/g,'"').replace(/&apos;/g,"'").replace(/&lt;/g,"<").replace(/&gt;/g,">").replace(/&amp;/g,"&"),r={},s=/<(\w)([-\w]+)(?:\/|[^>]*>((?:(?!<\1)[\s\S])*)<\/\1\2)>/gm,i;for(;i=s.exec(t);){let[,o,n,u]=i,a=o.toLowerCase()+n,c=u!=null?D(u):!0;typeof c=="string"?r[a]=L(e(c)):Array.isArray(r[a])?r[a].push(c):r[a]=r[a]!=null?[r[a],c]:Ie[a]?[c]:c}return Object.keys(r).length?r:e(t)};import _e from"avsc";var h={MISSING_ARGUMENT:"MISSING_ARGUMENT",COLLECTION_EXISTS:"COLLECTION_EXISTS",CREATE_COLLECTION_ERROR:"CREATE_COLLECTION_ERROR",RENAME_COLLECTION_ERROR:"RENAME_COLLECTION_ERROR",REMOVE_COLLECTION_ERROR:"REMOVE_COLLECTION_ERROR",UPDATE_COLLECTION_SCHEMA_ERROR:"UPDATE_COLLECTION_SCHEMA_ERROR",COLLECTION_NOT_FOUND:"COLLECTION_NOT_FOUND",SCHEMA_VALIDATION_ERROR:"SCHEMA_VALIDATION_ERROR",DOCUMENT_VALIDATION_ERROR:"DOCUMENT_VALIDATION_ERROR",S3_OPERATION_ERROR:"S3_OPERATION_ERROR",FIND_ERROR:"FIND_ERROR",FIND_ONE_ERROR:"FIND_ONE_ERROR",SAVE_DATA_ERROR:"SAVE_DATA_ERROR",INSERT_ERROR:"INSERT_ERROR",UPDATE_ERROR:"UPDATE_ERROR",UPDATE_ONE_ERROR:"UPDATE_ONE_ERROR",DELETE_ERROR:"DELETE_ERROR",COUNT_ERROR:"COUNT_ERROR",UNKNOWN_ERROR:"UNKNOWN_ERROR"},d=class extends Error{constructor(e,r=h.UNKNOWN_ERROR){super(`lowstorageError: ${e} :: code: ${r}`),this.name=this.constructor.name,this.code=r,Error.captureStackTrace(this,this.constructor)}};var $=class extends d{constructor(e){super(e,h.SCHEMA_VALIDATION_ERROR)}},T=class extends d{constructor(e){super(e,h.DOCUMENT_VALIDATION_ERROR)}},p=class extends d{constructor(e,r){super(`S3 ${r} operation failed: ${e}`,h.S3_OPERATION_ERROR)}};import{randomUUID as G}from"node:crypto";var k=(t,e)=>Object.keys(e).every(r=>t[r]===e[r]),le=async()=>typeof G<"u"&&typeof G=="function"?G():typeof crypto<"u"&&typeof crypto=="object"&&typeof crypto.randomUUID=="function"?crypto.randomUUID():"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(/[xy]/g,function(t){var e=Math.random()*16|0,r=t==="x"?e:e&3|8;return r.toString(16)}),ce=(t,e="SubAutoGenerated")=>{switch(typeof t){case"string":return Se(t)?{type:"string",name:"_id",size:16,logicalType:"UUID"}:"string";case"number":return Number.isInteger(t)?"int":"float";case"boolean":return"boolean";case"object":return t===null?"null":Array.isArray(t)?{type:"array",items:ce(t[0])}:V(t,e);default:return"string"}},v=t=>{let e={name:"_id",type:"string",size:16,logicalType:"UUID"};return typeof t>"u"||t===null||(t.type==="record"?t.fields.some(s=>s.name==="_id")||t.fields.unshift(e):t.type==="array"&&t.items.type==="record"&&(t.items.fields.some(s=>s.name==="_id")||t.items.fields.unshift(e))),t},V=(t,e="AutoGenerated")=>{Array.isArray(t)&&(t=t[0]);let r=Object.entries(t).map(([i,o])=>({name:i,type:ce(o,`${e}.${i}`)}));return v({type:"record",name:e,fields:r})},Se=t=>/^[0-9A-F]{8}-[0-9A-F]{4}-4[0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$/i.test(t);var l="lowstorage",I="/",B="lowstorage",A=".avro",be=1024*1024,ue=5*be,W=Buffer.from("","utf8"),z=(t=h.DOCUMENT_VALIDATION_ERROR)=>{throw new T(`${l}: Invalid document or schema`,t)},P=t=>{if(t.trim()===""||t===null||typeof t>"u"||t.length>255||t===null)throw new d(`${l}: Collection name is required, null or too long`,h.MISSING_ARGUMENT)},de=class{constructor(e={accessKeyId:void 0,secretAccessKey:void 0,endpoint:void 0,bucketName:void 0,region:"auto",logger:null,dirPrefix:B}){this._checkArgs(e),this._schemas=new Map,this._s3=new he(e),this._dirPrefix=e.dirPrefix||B,this._avro=_e}_checkArgs=e=>{let r=["accessKeyId","secretAccessKey","endpoint","bucketName"];for(let s of r)if(!e[s])throw new d(`${l}: ${s} is required`,h.MISSING_ARGUMENT)};async listCollections(){try{let e=await this._s3.list(I,this._dirPrefix);return typeof e=="object"&&e!==null&&e.keyCount==="0"?[]:e.map(r=>r.key.slice(this._dirPrefix.length+1,-A.length))}catch(e){throw new p(`${l}: ${e.message}`,h.S3_OPERATION_ERROR)}}async collectionExists(e){try{return P(e),!!await this._s3.fileExists(`${this._dirPrefix}${I}${e}${A}`)}catch(r){if(r.message.includes("Not Found"))return!1;throw new d(`${l}: ${r.message}`,h.COLLECTION_NOT_FOUND)}}async createCollection(e,r,s=[]){try{if(P(e),!await this.collectionExists(e)){if(typeof r<"u"&&r!==null)try{if(!this._avro.parse(r))throw new $(`${l}: Schema is invalid: ${r}`,h.SCHEMA_VALIDATION_ERROR)}catch{throw new $(`${l}: Schema is invalid: ${r}`,h.SCHEMA_VALIDATION_ERROR)}if(s.length>0&&r){let o=this._avro.parse({type:"array",items:r});await this._s3.put(`${this._dirPrefix}${I}${e}${A}`,o.toBuffer(s))}else await this._s3.put(`${this._dirPrefix}${I}${e}${A}`,W);return this.collection(e,r,!1)}throw new d(`${l}: Collection ${e} already exists`,h.COLLECTION_EXISTS)}catch(i){throw i instanceof d?i:new d(`${l}: ${i.message}`,h.CREATE_COLLECTION_ERROR)}}async removeCollection(e){try{if(P(e),await this.collectionExists(e)){await this._s3.delete(`${this._dirPrefix}${I}${e}${A}`);let s=await this.collectionExists(e);if(typeof s=="boolean"){if(!s)return this._schemas.delete(e),!0;throw new d(`${l}: Failed to delete collection ${e}`,h.S3_OPERATION_ERROR)}throw new p(`${l}: Failed to delete collection ${e}`,h.S3_OPERATION_ERROR)}throw new d(`${l}: Collection ${e} does not exist`,h.REMOVE_COLLECTION_ERROR)}catch(r){throw r instanceof p?r:new d(`${l}: Failed to remove collection: ${r.message}`,h.REMOVE_COLLECTION_ERROR)}}async collection(e,r,s=!0){try{P(e);let i=`${this._dirPrefix}${I}${e}${A}`;if(!await this._s3.fileExists(i)){if(!s)throw new d(`${l}: Collection ${e} does not exist`,h.COLLECTION_NOT_FOUND);await this._s3.put(i,W)}let n=r||this._schemas.get(e)||void 0;return new Q(e,n,this._s3,this._dirPrefix)}catch(i){throw i.message.includes("unknown type")?new $(`${l}: Schema input is invalid: ${i.message}`,h.SCHEMA_VALIDATION_ERROR):new d(`${l}: ${i.message}`,h.COLLECTION_NOT_FOUND)}}s3=()=>this._s3},Q=class t{constructor(e,r,s,i=B,o=!1,n=ue){this._colName=e,this._s3=s,this._schema=v(r),this._dirPrefix=i,this._safeWrite=o,this._chunkSize=n||ue,this._key=`${this._dirPrefix}${I}${this._colName}${A}`,this._s3.setMaxRequestSizeInBytes(this._chunkSize),this._avro=_e,this._lastETag="",this._dataCache=[],this._avroType=typeof r>"u"?null:this._avro.parse(r)}getProps=()=>({colName:this._colName,schema:this._schema,s3:this._s3,avro:this._avro,avroType:this._avroType,dirPrefix:this._dirPrefix,safeWrite:this._safeWrite,chunkSize:this._chunkSize});setProps=e=>{this._colName=e.colName,this._schema=e.schema,this._s3=e.s3,this._avro=e.avro,this._avroType=e.avroType,this._dirPrefix=e.dirPrefix,this._safeWrite=e.safeWrite,this._chunkSize=e.chunkSize};setSafeWrite=e=>{this._safeWrite=e};getSafeWrite=()=>this._safeWrite;getAvroSchema=()=>this._schema;setAvroSchema=e=>{this._schema=v(e),this._avroType=typeof e>"u"?null:this._avro.parse(e)};async _loadData(){try{if(this._avroType===null||typeof this._avroType>"u")throw new d(`${l}: Missing type definition. Configure before operations `,h.SCHEMA_VALIDATION_ERROR);let{etag:e,data:r}=await this._s3.getObjectWithETag(this._key,{"if-none-match":this._lastETag});if(r===null)return this._dataCache;this._lastETag=e===null?this._lastETag:e;let s=this._avro.parse({type:"array",items:this._avroType});if(r.length<this._chunkSize)return this._dataCache=r.length>0?s.fromBuffer(Buffer.from(r,"utf8")):[],this._dataCache;let i=this._chunkSize,o=[Buffer.from(r,"utf8")],n=!0;for(;n;){let a=await this._s3.getResponse(this._key,!1,i,i+this._chunkSize),c=await a.text();o.push(Buffer.from(c,"utf8")),i+=this._chunkSize,(a.headers.get("content-length")||c.length)<this._chunkSize&&(n=!1)}let u=Buffer.concat(o);return this._dataCache=s.fromBuffer(u),this._dataCache}catch(e){if(e.toString().indexOf("status 404: Unknown - Not Found")>-1)return this._dataCache=[],this._dataCache;throw new p(`${l}: Failed to load data: ${e.message}`,h.S3_OPERATION_ERROR)}}async _saveData(e){try{if(this._avroType===null||typeof this._avroType>"u")throw new d(`${l}: Missing type definition. Configure before operations `,h.SCHEMA_VALIDATION_ERROR);let r=this._avro.parse({type:"array",items:this._avroType}),s=e.length>0?r.toBuffer(e):W;if(this._safeWrite&&this._lastETag!==""){let n=await this._s3.getEtag(this._key);if(n!==null&&n!==this._lastETag)return!1}let i=await this._s3.put(this._key,s);if(i.status!==200)throw new p(`${l}: Failed to save data`,h.S3_OPERATION_ERROR);let o=i.headers.get("etag");return o&&(this._lastETag=this._s3.sanitizeETag(o),this._dataCache=e),!0}catch(r){throw r instanceof p?r:new d(`${l}: ${r.message}`,h.SAVE_DATA_ERROR)}}async insert(e,r=void 0){try{if(e==null)throw new d(`${l}: Document is required for insert`,h.INSERT_ERROR);if(typeof e!="object"&&!Array.isArray(e))throw new T(`${l}: Document must be an object or an array`,h.DOCUMENT_VALIDATION_ERROR);let s=Array.isArray(e)?e:[e],i=v(r)||this._schema||V(s[0]),o=this._avro.parse(i);if(!o)throw new $(`${l}: Schema is required - Pass a schema to the insert method`,h.SCHEMA_VALIDATION_ERROR);this._avroType=o;let n=await this._loadData();for(let a of s){if(typeof a!="object"||a===null)throw new T(`${l}: Invalid input: input must be an object or an array of objects`,h.DOCUMENT_VALIDATION_ERROR);if(a._id=a._id||await le(),this._avroType.isValid(a,{errorHook:z,noUndeclaredFields:!0})===!0)n.push(a);else throw new T(`${l}: Invalid document or schema`,h.DOCUMENT_VALIDATION_ERROR)}if(!await this._saveData(n))throw new p(`${l}: Failed to insert document`,h.S3_OPERATION_ERROR);return this.setAvroSchema(i),s}catch(s){throw s.message.includes("unknown type")?new $(`${l}: Schema input is invalid: ${s.message}`,h.SCHEMA_VALIDATION_ERROR):s instanceof d?s:new d(`${l} Insert operation failed: ${s.message}`,h.INSERT_ERROR)}}async find(e={},r={}){try{if(e==null)throw new d(`${l}: Query is required for update`,h.MISSING_ARGUMENT);let s=await this._loadData(),i=parseInt(r.skip,10)||0,o=parseInt(r.limit,10)?i+parseInt(r.limit,10):void 0;return s.filter(u=>k(u,e)).slice(i,o)}catch(s){throw new d(`${l}: Find operation failed: ${s.message}`,h.FIND_ERROR)}}async findOne(e={}){try{if(e===null)throw new d(`${l}: Query cannot be null`,h.INVALID_ARGUMENT);return(await this.find(e,{limit:1}))[0]||null}catch(r){throw r instanceof d?r:new d(`${l}: FindOne operation failed: ${r.message}`,h.FIND_ONE_ERROR)}}async update(e={},r={},s={}){try{if(e==null||r===void 0||r===null)throw new d(`${l}: Query and update values are required for update`,h.MISSING_ARGUMENT);if(!this._avroType)throw new $(`${l}: Schema is not defined for this collection`,h.SCHEMA_VALIDATION_ERROR);let i=await this._loadData();if(i.length===0)return 0;let o=0;for(let n=0;n<i.length;n++)if(k(i[n],e)){let u={...i[n],...r};if(this._avroType.isValid(u,{errorHook:z,noUndeclaredFields:!0})===!0)i[n]=u,o++;else throw new T(`${l}: Invalid document or schema`,h.DOCUMENT_VALIDATION_ERROR)}if(o>0){if(!await this._saveData(i))throw new p(`${l}: Failed to update document`,h.S3_OPERATION_ERROR)}else if(s.upsert){if(!await this.insert(r))throw new p(`${l}: Failed to update document`,h.S3_OPERATION_ERROR);o=1}return o}catch(i){throw i instanceof p?i:new d(`${l}: Update operation failed: ${i.message}`,h.UPDATE_ERROR)}}async updateOne(e={},r={},s={}){try{if(e==null||r===void 0||r===null)throw new d(`${l}: Query is required`,h.MISSING_ARGUMENT);if(!this._avroType)throw new $(`${l}: Schema is not defined for this collection`,h.SCHEMA_VALIDATION_ERROR);let i=await this._loadData();if(i.length===0)return 0;let o=i.findIndex(n=>k(n,e));if(o!==-1){let n={...i[o],...r};if(this._avroType.isValid(n,{errorHook:z,noUndeclaredFields:!0})===!0){if(i[o]=n,!await this._saveData(i))throw new p(`${l}: Failed to update document`,h.S3_OPERATION_ERROR);return 1}else throw new T(`${l}: Invalid document or schema`,h.DOCUMENT_VALIDATION_ERROR)}if(s.upsert){if(!await this.insert(r))throw new p(`${l}: Failed to update document`,h.S3_OPERATION_ERROR);return 1}return 0}catch(i){throw i instanceof d?i:new d(`${l}: UpdateOne operation failed: ${i.message}`,h.UPDATE_ONE_ERROR)}}async delete(e={}){try{if(e==null)throw new d(`${l}: Query is required`,h.MISSING_ARGUMENT);let r=await this._loadData();if(r.length===0)return 0;let s=r.length,i=r.filter(n=>!k(n,e));if(!await this._saveData(i))throw new p(`${l}: Failed to delete document`,h.S3_OPERATION_ERROR);return s-i.length}catch(r){throw r instanceof p?r:new d(`${l}: Delete operation failed: ${r.message}`,h.DELETE_ERROR)}}async deleteAll(){try{let r=(await this._loadData()).length;if(!await this._saveData([]))throw new p(`${l}: Failed to delete document`,h.S3_OPERATION_ERROR);return r}catch(e){throw e instanceof p?e:new d(`${l}: Delete operation failed: ${e.message}`,h.DELETE_ERROR)}}async count(e={}){try{return(await this.find(e)).length}catch(r){throw new d(`${l}: Count operation failed: ${r.message}`,h.COUNT_ERROR)}}async renameCollection(e,r=this._schema){try{if(P(e),await this._s3.fileExists(`${this._dirPrefix}${I}${e}${A}`))throw new d(`${l}: Collection ${e} already exists`,h.COLLECTION_EXISTS);let i=r||this.getAvroSchema(),o=await this._loadData(),n=new t(e,i,this._s3,this._dirPrefix,this._safeWrite,this._chunkSize);return await n._saveData(o),await this._s3.delete(`${this._dirPrefix}${I}${this._colName}${A}`),n}catch(s){throw s instanceof d?s:new d(`${l}: Rename collection failed: ${s.message}`,h.RENAME_COLLECTION_ERROR)}}};export{de as lowstorage,d as lowstorageError,h as lowstorage_ERROR_CODES};
//# sourceMappingURL=lowstorage.js.map
